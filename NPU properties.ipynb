{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NPU device properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CPU', 'NPU']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openvino as ov\n",
    "\n",
    "core = ov.Core()\n",
    "core.available_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Intel(R) AI Boost'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openvino.properties as props\n",
    "\n",
    "\n",
    "device = \"NPU\"\n",
    "\n",
    "core.get_property(device, props.device.full_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all properties "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NPU SUPPORTED_PROPERTIES:\n",
      "\n",
      "AVAILABLE_DEVICES               : ['3720']\n",
      "CACHE_DIR                       : \n",
      "COMPILATION_NUM_THREADS         : 20\n",
      "DEVICE_ARCHITECTURE             : 3720\n",
      "DEVICE_GOPS                     : {<Type: 'bfloat16'>: 0.0, <Type: 'float16'>: 6553.60009765625, <Type: 'float32'>: 0.0, <Type: 'int8_t'>: 13107.2001953125, <Type: 'uint8_t'>: 13107.2001953125}\n",
      "DEVICE_ID                       : \n",
      "DEVICE_PCI_INFO                 : {domain: 0 bus: 0 device: 0xb function: 0}\n",
      "DEVICE_TYPE                     : Type.INTEGRATED\n",
      "DEVICE_UUID                     : 80d1d11eb73811eab3de0242ac130004\n",
      "ENABLE_CPU_PINNING              : False\n",
      "EXECUTION_DEVICES               : NPU\n",
      "EXECUTION_MODE_HINT             : ExecutionMode.PERFORMANCE\n",
      "FULL_DEVICE_NAME                : Intel(R) AI Boost\n",
      "INFERENCE_PRECISION_HINT        : <Type: 'float16'>\n",
      "LOG_LEVEL                       : Level.ERR\n",
      "MODEL_PRIORITY                  : Priority.MEDIUM\n",
      "NPU_BYPASS_UMD_CACHING          : False\n",
      "NPU_COMPILATION_MODE_PARAMS     : \n",
      "NPU_DEVICE_ALLOC_MEM_SIZE       : 0\n",
      "NPU_DEVICE_TOTAL_MEM_SIZE       : 17179869184\n",
      "NPU_DRIVER_VERSION              : 3104\n",
      "NPU_MAX_TILES                   : 2\n",
      "NPU_TILES                       : -1\n",
      "NPU_TURBO                       : False\n",
      "NUM_STREAMS                     : 1\n",
      "OPTIMAL_NUMBER_OF_INFER_REQUESTS: 1\n",
      "OPTIMIZATION_CAPABILITIES       : ['FP16', 'INT8', 'EXPORT_IMPORT']\n",
      "PERFORMANCE_HINT                : PerformanceMode.LATENCY\n",
      "PERFORMANCE_HINT_NUM_REQUESTS   : 1\n",
      "PERF_COUNT                      : False\n",
      "RANGE_FOR_ASYNC_INFER_REQUESTS  : (1, 10, 1)\n",
      "RANGE_FOR_STREAMS               : (1, 4)\n",
      "WORKLOAD_TYPE                   : WorkloadType.DEFAULT\n"
     ]
    }
   ],
   "source": [
    "print(f\"{device} SUPPORTED_PROPERTIES:\\n\")\n",
    "supported_properties = core.get_property(device, props.supported_properties)\n",
    "indent = len(max(supported_properties, key=len))\n",
    "\n",
    "for property_key in supported_properties:\n",
    "    if property_key not in (\"SUPPORTED_METRICS\", \"SUPPORTED_CONFIG_KEYS\", \"SUPPORTED_PROPERTIES\"):\n",
    "        try:\n",
    "            property_val = core.get_property(device, property_key)\n",
    "        except TypeError:\n",
    "            property_val = \"UNSUPPORTED TYPE\"\n",
    "        print(f\"{property_key:<{indent}}: {property_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download a model from the hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read IR model from artifacts\\ir_model\\resnet50_fp16.xml\n"
     ]
    }
   ],
   "source": [
    "import huggingface_hub as hf_hub\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# create a directory for resnet model file\n",
    "MODEL_DIRECTORY_PATH = Path(\"artifacts\")\n",
    "MODEL_DIRECTORY_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "model_name = \"resnet50\"\n",
    "\n",
    "precision = \"FP16\"\n",
    "\n",
    "model_path = MODEL_DIRECTORY_PATH / \"ir_model\" / f\"{model_name}_{precision.lower()}.xml\"\n",
    "\n",
    "model = None\n",
    "if not model_path.exists():\n",
    "    hf_hub.snapshot_download(\"katuni4ka/resnet50_fp16\", local_dir=model_path.parent)\n",
    "    print(\"IR model saved to {}\".format(model_path))\n",
    "    model = core.read_model(model_path)\n",
    "else:\n",
    "    print(\"Read IR model from {}\".format(model_path))\n",
    "    model = core.read_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<CompiledModel:\n",
       "inputs[\n",
       "<ConstOutput: names[x] shape[1,3,224,224] type: f32>\n",
       "]\n",
       "outputs[\n",
       "<ConstOutput: names[x.45] shape[1,1000] type: f32>\n",
       "]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_model = core.compile_model(model, device)\n",
    "compiled_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance hints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openvino.properties.hint as hints\n",
    "\n",
    "\n",
    "compiled_model = core.compile_model(model, device, {hints.performance_mode(): hints.PerformanceMode.LATENCY})\n",
    "\n",
    "# compiled_model = core.compile_model(model, device, {hints.performance_mode(): hints.PerformanceMode.THROUGHPUT})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
